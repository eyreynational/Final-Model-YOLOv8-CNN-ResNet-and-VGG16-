{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyreynational/Final-Model-YOLOv8-CNN-ResNet-and-VGG16-/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYbknPfwyk_k",
        "outputId": "ada2bb44-0685-47a1-8f90-cee244d0fdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siDDe29P6Tbk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import os\n",
        "# Tensorflow Libraries\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "# System libraries\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# Visualization Libraries\n",
        "import matplotlib.cm as cm\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from cycler import cycler\n",
        "import textwrap\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDQRSyQeyDCj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCGd_DdiyDCy"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/Master/Dataset/trian'  # Update with your path\n",
        "test_dir = '/content/drive/MyDrive/Master/Dataset/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CfKiSTuzX2_",
        "outputId": "f60422c0-8224-42f8-9dfc-5711948cba9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Master/Dataset/trian\n",
            "4096\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get the shape (dimensions) of the training directory\n",
        "train_dir_shape = os.path.abspath(train_dir)\n",
        "print(train_dir_shape)\n",
        "\n",
        "# If you want the size of training dir\n",
        "train_dir_size = os.path.getsize(train_dir)\n",
        "print(train_dir_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgM9pOA9y2N0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define a function to count images in each category\n",
        "def count_images_per_category(directory):\n",
        "    category_counts = {}\n",
        "    for category in os.listdir(directory):\n",
        "        category_path = os.path.join(directory, category)\n",
        "        if os.path.isdir(category_path):  # Check if it's a directory\n",
        "            category_counts[category] = len(os.listdir(category_path))\n",
        "    return category_counts\n",
        "\n",
        "# Count images in training and testing sets\n",
        "train_counts = count_images_per_category(train_dir)\n",
        "test_counts = count_images_per_category(test_dir)\n",
        "\n",
        "# Create a bar chart\n",
        "categories = list(train_counts.keys())  # Get category names\n",
        "train_values = list(train_counts.values())  # Get image counts for training set\n",
        "test_values = list(test_counts.values())  # Get image counts for testing set\n",
        "\n",
        "x = np.arange(len(categories))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, train_values, width, label='Train')\n",
        "rects2 = ax.bar(x + width/2, test_values, width, label='Test')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Number of Images')\n",
        "ax.set_title('Dataset Distribution by Category')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories, rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels to the bars\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU9pzE6CzxLk"
      },
      "outputs": [],
      "source": [
        "img_size = (256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt6VLoLWzy2w"
      },
      "outputs": [],
      "source": [
        "# Function to load images and their labels from a directory\n",
        "def load_images_from_dir(directory, img_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    # List only subdirectories (each corresponding to a category)\n",
        "    categories = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(directory, category)\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            # Read the image using cv2 (in BGR format)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                # Resize to the common size (256x256)\n",
        "                img = cv2.resize(img, img_size)\n",
        "                images.append(img)\n",
        "                labels.append(category)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FmmD7GTN56EY",
        "outputId": "71f5992a-a790-45d1-cc58-ee8c7f928972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (1400, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "# Load training images and labels\n",
        "X_train, y_train = load_images_from_dir(train_dir, img_size)\n",
        "print(\"Training data shape:\", X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zgBSIBBi58ay",
        "outputId": "31e1b554-2410-4aea-aef5-f738a197878e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flattened image shape: (1400, 196608)\n"
          ]
        }
      ],
      "source": [
        "# Flatten each image into a 1D vector\n",
        "n_samples = X_train.shape[0]\n",
        "X_flat = X_train.reshape(n_samples, -1)\n",
        "print(\"Flattened image shape:\", X_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kKij4jLW592I"
      },
      "outputs": [],
      "source": [
        "# Standardize the pixel values (mean=0, std=1)\n",
        "from sklearn.preprocessing import StandardScaler # Import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_flat.astype(np.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KMnljPZ5_lj"
      },
      "outputs": [],
      "source": [
        "# Apply PCA to retain 95% of the variance\n",
        "from sklearn.decomposition import PCA  # Import PCA here\n",
        "pca = PCA(n_components=0.95, svd_solver='full')\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "print(\"PCA reduced shape:\", X_pca.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zIdKgpK6A4h"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = load_images_from_dir(test_dir, img_size)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "X_test_scaled = scaler.transform(X_test_flat.astype(np.float64))\n",
        "X_test_pca = pca.transform(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H3jjC8g6Cl9"
      },
      "outputs": [],
      "source": [
        "# Plot the cumulative explained variance ratio to see how many components were selected\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('PCA Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfJD6QQe6I86"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data Augmentation for the Training Set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'            # Fill mode for shifts\n",
        ")\n",
        "\n",
        "# For the Test Set, only rescale\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training set\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # For multi-class classification\n",
        ")\n",
        "\n",
        "# Load the test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Check Class Balance\n",
        "print(\"Class distribution in training set:\", Counter(train_generator.classes))\n",
        "print(\"Class distribution in test set:\", Counter(test_generator.classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP__SYmp4Ag0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvYSjX266ISZ"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Use train_generator.class_indices to get the number of classes\n",
        "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oMlNjHZdyDC4"
      },
      "outputs": [],
      "source": [
        "# Ensure ReduceLROnPlateau is imported\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=70,\n",
        "    validation_data=test_generator,  # Pass the test_generator here\n",
        "    callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsgEjKxNyDC6"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOjOQqr8CBDF"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "train_loss, train_acc = model.evaluate(train_generator, verbose=2)\n",
        "print(f\"Train Accuracy: {train_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-_C9oqNCKU2"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "Y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB2GGMaLCMkC"
      },
      "outputs": [],
      "source": [
        "# Classification report for precision, recall, f1-score\n",
        "print('Classification Report')\n",
        "target_names = ['Powdery_mildew', 'Bacterial_spot', 'Late_blight', 'Healthy', 'Mosaic_virus']\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names,digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkhJnIqgCoKM"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix for detailed error analysis\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_generator.classes, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxVJcClSCp-E"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix # Import confusion_matrix\n",
        "\n",
        "# Get predictions for the test set\n",
        "y_pred = model.predict(test_generator).argmax(axis=1)  # Get predicted class labels\n",
        "\n",
        "conf_matrix = confusion_matrix(test_generator.classes, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=test_generator.class_indices,\n",
        "            yticklabels=test_generator.class_indices)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}